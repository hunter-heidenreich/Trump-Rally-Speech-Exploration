{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the dataset\n",
    "# update with a path pointing to the dataset on your own machine!\n",
    "path = '/Users/hsh28/data/trump_stumps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/hsh28/data/trump_stumps/FayettevilleSep9_2019.txt',\n",
       " '/Users/hsh28/data/trump_stumps/TupeloNov1_2019.txt',\n",
       " '/Users/hsh28/data/trump_stumps/NewHampshireAug15_2019.txt',\n",
       " '/Users/hsh28/data/trump_stumps/HendersonSep13_2020.txt',\n",
       " '/Users/hsh28/data/trump_stumps/OhioSep21_2020.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gathering all text filenames in the directory\n",
    "fps = glob(path + '*.txt')\n",
    "fps[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FayettevilleSep9_2019.txt has 1 lines!\n",
      "TupeloNov1_2019.txt has 1 lines!\n",
      "NewHampshireAug15_2019.txt has 1 lines!\n",
      "HendersonSep13_2020.txt has 1 lines!\n",
      "OhioSep21_2020.txt has 1 lines!\n",
      "PhoenixFeb19_2020.txt has 1 lines!\n",
      "BattleCreekDec19_2019.txt has 1 lines!\n",
      "PittsburghSep22_2020.txt has 1 lines!\n",
      "TexasSep23_2019.txt has 1 lines!\n",
      "ColoradorSpringsFeb20_2020.txt has 1 lines!\n",
      "LatrobeSep3_2020.txt has 1 lines!\n",
      "DallasOct17_2019.txt has 1 lines!\n",
      "DesMoinesJan30_2020.txt has 1 lines!\n",
      "MinneapolisOct10_2019.txt has 1 lines!\n",
      "YumaAug18_2020.txt has 1 lines!\n",
      "ToledoJan9_2020.txt has 1 lines!\n",
      "CharlotteMar2_2020.txt has 1 lines!\n",
      "Winston-SalemSep8_2020.txt has 1 lines!\n",
      "TulsaJun20_2020.txt has 1 lines!\n",
      "NewMexicoSep16_2019.txt has 1 lines!\n",
      "HersheyDec10_2019.txt has 1 lines!\n",
      "NewHampshireFeb10_2020.txt has 1 lines!\n",
      "LasVegasFeb21_2020.txt has 1 lines!\n",
      "NewHampshireAug28_2020.txt has 1 lines!\n",
      "MindenSep12_2020.txt has 1 lines!\n",
      "FreelandSep10_2020.txt has 1 lines!\n",
      "CharlestonFeb28_2020.txt has 1 lines!\n",
      "MosineeSep17_2020.txt has 1 lines!\n",
      "MilwaukeeJan14_2020.txt has 1 lines!\n",
      "LexingtonNov4_2019.txt has 1 lines!\n",
      "BemidjiSep18_2020.txt has 1 lines!\n",
      "CincinnatiAug1_2019.txt has 1 lines!\n",
      "FayettevilleSep19_2020.txt has 1 lines!\n",
      "WildwoodJan28_2020.txt has 1 lines!\n",
      "GreenvilleJul17_2019.txt has 1 lines!\n"
     ]
    }
   ],
   "source": [
    "# where we'll store all the data of our speeches\n",
    "data = {}\n",
    "for f in fps:\n",
    "    # name will be the direct filename, without prefix path\n",
    "    name = f.split('/')[-1]\n",
    "    \n",
    "    # read the lines of the speech\n",
    "    with open(f) as ff:\n",
    "        lines = ff.readlines()\n",
    "    \n",
    "    # Understanding how many lines each speech has\n",
    "    # Hint: It should just be 1\n",
    "    print(f'{name} has {len(lines)} lines!')\n",
    "        \n",
    "    data[name] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FayettevilleSep9_2019.txt     :\t50472 chars\n",
      "TupeloNov1_2019.txt           :\t51128 chars\n",
      "NewHampshireAug15_2019.txt    :\t55388 chars\n",
      "HendersonSep13_2020.txt       :\t49082 chars\n",
      "OhioSep21_2020.txt            :\t58316 chars\n",
      "PhoenixFeb19_2020.txt         :\t52640 chars\n",
      "BattleCreekDec19_2019.txt     :\t95760 chars\n",
      "PittsburghSep22_2020.txt      :\t65020 chars\n",
      "TexasSep23_2019.txt           :\t14610 chars\n",
      "ColoradorSpringsFeb20_2020.txt:\t63122 chars\n",
      "LatrobeSep3_2020.txt          :\t67534 chars\n",
      "DallasOct17_2019.txt          :\t57081 chars\n",
      "DesMoinesJan30_2020.txt       :\t64514 chars\n",
      "MinneapolisOct10_2019.txt     :\t63409 chars\n",
      "YumaAug18_2020.txt            :\t34470 chars\n",
      "ToledoJan9_2020.txt           :\t58727 chars\n",
      "CharlotteMar2_2020.txt        :\t37173 chars\n",
      "Winston-SalemSep8_2020.txt    :\t60811 chars\n",
      "TulsaJun20_2020.txt           :\t61155 chars\n",
      "NewMexicoSep16_2019.txt       :\t63291 chars\n",
      "HersheyDec10_2019.txt         :\t54664 chars\n",
      "NewHampshireFeb10_2020.txt    :\t36830 chars\n",
      "LasVegasFeb21_2020.txt        :\t74654 chars\n",
      "NewHampshireAug28_2020.txt    :\t49376 chars\n",
      "MindenSep12_2020.txt          :\t76668 chars\n",
      "FreelandSep10_2020.txt        :\t54931 chars\n",
      "CharlestonFeb28_2020.txt      :\t51794 chars\n",
      "MosineeSep17_2020.txt         :\t78082 chars\n",
      "MilwaukeeJan14_2020.txt       :\t52215 chars\n",
      "LexingtonNov4_2019.txt        :\t49737 chars\n",
      "BemidjiSep18_2020.txt         :\t89735 chars\n",
      "CincinnatiAug1_2019.txt       :\t44934 chars\n",
      "FayettevilleSep19_2020.txt    :\t87029 chars\n",
      "WildwoodJan28_2020.txt        :\t38989 chars\n",
      "GreenvilleJul17_2019.txt      :\t58149 chars\n"
     ]
    }
   ],
   "source": [
    "# where we'll store all the data of our speeches\n",
    "# a revision of above since we know that each file is 1 line\n",
    "data = {}\n",
    "for f in fps:\n",
    "    # name will be the direct filename, without prefix path\n",
    "    name = f.split('/')[-1]\n",
    "    \n",
    "    # read the lines of the speech\n",
    "    with open(f) as ff:\n",
    "        text = ff.readlines()[0]\n",
    "    \n",
    "    # Print the number of characters in each speech!\n",
    "    print(f'{name:30}:\\t{len(text)} chars')\n",
    "        \n",
    "    data[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Our simple function that takes a text and splits \n",
    "    it into token entities!\n",
    "    \"\"\"\n",
    "    return [t.lower() for t in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14103),\n",
       " ('and', 11188),\n",
       " ('to', 9251),\n",
       " ('a', 7872),\n",
       " ('i', 7421),\n",
       " ('of', 6770),\n",
       " ('we', 6397),\n",
       " ('you', 6361),\n",
       " ('they', 5491),\n",
       " ('in', 4329),\n",
       " ('that', 4106),\n",
       " ('have', 3770),\n",
       " ('it', 3426),\n",
       " ('but', 2932),\n",
       " ('is', 2582),\n",
       " ('for', 2494),\n",
       " ('he', 2472),\n",
       " ('was', 2436),\n",
       " (\"it's\", 2412),\n",
       " ('going', 2260)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are Trump's most common words/tokens in these speeches? \n",
    "cnt = Counter()\n",
    "for name, text in data.items():\n",
    "    cnt += Counter(tokenize(text))\n",
    "\n",
    "# as one would guess, these are pretty much just stop words!\n",
    "cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['count.', 'important.', 'nothing', 'situation,', 'allies', 'said,', 'future,', '45', 'path,', 'compare']\n"
     ]
    }
   ],
   "source": [
    "# Are there words only mentioned in some speeches but never in any others?\n",
    "word_forms = defaultdict(set)\n",
    "for name, text in data.items():\n",
    "    word_forms[name] = set(tokenize(text))\n",
    "\n",
    "# A random sampling of some of the words in a speech\n",
    "print(list(word_forms['FayettevilleSep9_2019.txt'])[:10])\n",
    "\n",
    "unique_forms = defaultdict(set)\n",
    "for speech_x, forms_x in word_forms.items():\n",
    "    unique_forms[speech_x] = forms_x\n",
    "    for speech_y, forms_y in word_forms.items():\n",
    "        if speech_x == speech_y:\n",
    "            continue\n",
    "        \n",
    "        unique_forms[speech_x] -= forms_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FayettevilleSep9_2019.txt\n",
      "Found 189 unique words.\n",
      "Previewing upto 7 random ones: ['formation', '2026.', 'fixed,', 'bishop?', 'yep,', 'cutters?\"', 'approval,'])\n",
      "-------------------------\n",
      "\n",
      "TupeloNov1_2019.txt\n",
      "Found 251 unique words.\n",
      "Previewing upto 7 random ones: ['nature.', 'museum.', 'elvis', 'misdeeds,', 'phil.', 'pardon.', 'a-flailing?'])\n",
      "-------------------------\n",
      "\n",
      "NewHampshireAug15_2019.txt\n",
      "Found 216 unique words.\n",
      "Previewing upto 7 random ones: ['weakened', 'time?\"', 'tubes,', 'elected.\"', 'europe.\".', 'rerun', 'infested.\"'])\n",
      "-------------------------\n",
      "\n",
      "HendersonSep13_2020.txt\n",
      "Found 215 unique words.\n",
      "Previewing upto 7 random ones: ['manifesto?', 'makeâ€¦\"', 'record-setting', 'pennant.', 'bars.', 'art.', 'prisons.'])\n",
      "-------------------------\n",
      "\n",
      "OhioSep21_2020.txt\n",
      "Found 227 unique words.\n",
      "Previewing upto 7 random ones: ['constitutionally', '4th', 'error.', 'kamilla?', '\"no.\"', 'insurmountable', 'oakland.'])\n",
      "-------------------------\n",
      "\n",
      "PhoenixFeb19_2020.txt\n",
      "Found 235 unique words.\n",
      "Previewing upto 7 random ones: ['union?', 'phoenix,', 'path,', 'pounded', 'perot', 'one-third', 'midtown.'])\n",
      "-------------------------\n",
      "\n",
      "BattleCreekDec19_2019.txt\n",
      "Found 504 unique words.\n",
      "Previewing upto 7 random ones: ['could.\"', 'weeks?', 'greatestâ€¦', 'asâ€¦', 'obamaâ€¦\"', 'last,', 'suckers,'])\n",
      "-------------------------\n",
      "\n",
      "PittsburghSep22_2020.txt\n",
      "Found 314 unique words.\n",
      "Previewing upto 7 random ones: ['italy?', 'imagined.', 'goodnight.', 'tuna.', '90.', 'begun', 'elon'])\n",
      "-------------------------\n",
      "\n",
      "TexasSep23_2019.txt\n",
      "Found 137 unique words.\n",
      "Previewing upto 7 random ones: ['invest,', 'brouillette,', 'deputy', 'amd', 'pro-growth', 'basketball.', 'tons'])\n",
      "-------------------------\n",
      "\n",
      "ColoradorSpringsFeb20_2020.txt\n",
      "Found 361 unique words.\n",
      "Previewing upto 7 random ones: ['39%.', 'denver', 'imitate', 'honey.', 'collins,', 'flop', 'teams'])\n",
      "-------------------------\n",
      "\n",
      "LatrobeSep3_2020.txt\n",
      "Found 368 unique words.\n",
      "Previewing upto 7 random ones: ['changing,', 'anti-energy', 'ordinance.', 'white.', 'personal.', 'softer,', 'john?\"'])\n",
      "-------------------------\n",
      "\n",
      "DallasOct17_2019.txt\n",
      "Found 326 unique words.\n",
      "Previewing upto 7 random ones: ['title.', 'queens.', 'lone', 'judges.\"', 'experiment', 'deere', 'leftover'])\n",
      "-------------------------\n",
      "\n",
      "DesMoinesJan30_2020.txt\n",
      "Found 357 unique words.\n",
      "Previewing upto 7 random ones: ['comparison.', '\"joe,', 'ex-governor', 'against,', 'transparencies,', 'millennials,', 'shockingly,'])\n",
      "-------------------------\n",
      "\n",
      "MinneapolisOct10_2019.txt\n",
      "Found 434 unique words.\n",
      "Previewing upto 7 random ones: ['homeland.', 'aluminum', 'placed', 'president,\"', 'adventures.', 'starts.', '269.'])\n",
      "-------------------------\n",
      "\n",
      "YumaAug18_2020.txt\n",
      "Found 235 unique words.\n",
      "Previewing upto 7 random ones: ['prosecution', 'paul?', 'everlasting', 'my,', '\"most', 'boss.', 'mcsally'])\n",
      "-------------------------\n",
      "\n",
      "ToledoJan9_2020.txt\n",
      "Found 352 unique words.\n",
      "Previewing upto 7 random ones: ['qasam', 'anyplace', 'offices', 'true?\"', 'beyond.', 'saved.', 'brighter,'])\n",
      "-------------------------\n",
      "\n",
      "CharlotteMar2_2020.txt\n",
      "Found 196 unique words.\n",
      "Previewing upto 7 random ones: ['bussey,', 'thursday.', 'thom,', 'duper.', 'plummeted,', 'mistakes,', 'them!'])\n",
      "-------------------------\n",
      "\n",
      "Winston-SalemSep8_2020.txt\n",
      "Found 300 unique words.\n",
      "Previewing upto 7 random ones: ['owner,\"', 'meantime', 'surge,', 'wheel,', 'preaching', 'chart,', '56'])\n",
      "-------------------------\n",
      "\n",
      "TulsaJun20_2020.txt\n",
      "Found 502 unique words.\n",
      "Previewing upto 7 random ones: ['$50,000.00', 'daca', 'inslee', 'stoking', 'stadiums?', 'shameless', 'elite,\"'])\n",
      "-------------------------\n",
      "\n",
      "NewMexicoSep16_2019.txt\n",
      "Found 464 unique words.\n",
      "Previewing upto 7 random ones: ['serve', 'entry,', 'essentially,', 'areas,', '730', 'greatness', 'offshoring,'])\n",
      "-------------------------\n",
      "\n",
      "HersheyDec10_2019.txt\n",
      "Found 470 unique words.\n",
      "Previewing upto 7 random ones: ['thumb', 'officeâ€¦', 'contained', 'corrupted', 'arabia.', 'coverage', 'conspired'])\n",
      "-------------------------\n",
      "\n",
      "NewHampshireFeb10_2020.txt\n",
      "Found 258 unique words.\n",
      "Previewing upto 7 random ones: ['scalise.', 'energized,', 'cried.', 'behavior', '104', 'morse.', 'sighed'])\n",
      "-------------------------\n",
      "\n",
      "LasVegasFeb21_2020.txt\n",
      "Found 606 unique words.\n",
      "Previewing upto 7 random ones: [\"that'll\", 'sands', 'precedent.', 'stopped?', 'scavino.', '\"i,\"', 'vegas.'])\n",
      "-------------------------\n",
      "\n",
      "NewHampshireAug28_2020.txt\n",
      "Found 421 unique words.\n",
      "Previewing upto 7 random ones: ['railroads.', \"night's\", 'massachusetts', 'floyd.', 'lawyers.', 'lou.', 'baldasaro'])\n",
      "-------------------------\n",
      "\n",
      "MindenSep12_2020.txt\n",
      "Found 618 unique words.\n",
      "Previewing upto 7 random ones: ['terror-afflicted', 'settled,', 'taxed', 'vandals,', 'haircut,', 'mentioned.', 'pathetic'])\n",
      "-------------------------\n",
      "\n",
      "FreelandSep10_2020.txt\n",
      "Found 469 unique words.\n",
      "Previewing upto 7 random ones: ['locks,', 'ventilator,', 'caused', 'fools.', 'junge?', 'israel.\"', 'bored.'])\n",
      "-------------------------\n",
      "\n",
      "CharlestonFeb28_2020.txt\n",
      "Found 489 unique words.\n",
      "Previewing upto 7 random ones: ['count.', 'committee.', 'timeâ€¦', 'paper.', 'reciprocal.', 'steyer', '31st,'])\n",
      "-------------------------\n",
      "\n",
      "MosineeSep17_2020.txt\n",
      "Found 811 unique words.\n",
      "Previewing upto 7 random ones: ['situation,', 'straw', \"sheriff's\", 'osama', 'difficult', 'information,', 'raises'])\n",
      "-------------------------\n",
      "\n",
      "MilwaukeeJan14_2020.txt\n",
      "Found 561 unique words.\n",
      "Previewing upto 7 random ones: ['warned', 'helicopters', 'designate', 'out?', 'maga,', 'community,', 'government.'])\n",
      "-------------------------\n",
      "\n",
      "LexingtonNov4_2019.txt\n",
      "Found 582 unique words.\n",
      "Previewing upto 7 random ones: ['becoming', 'cooler', 'needed', 'administrations', 'obliterate', 'wildcats.', '60,000?\"'])\n",
      "-------------------------\n",
      "\n",
      "BemidjiSep18_2020.txt\n",
      "Found 1235 unique words.\n",
      "Previewing upto 7 random ones: ['hears', 'information', 'negotiator', 'mar-a-largo', '50.', 'ruins.', 'commercials'])\n",
      "-------------------------\n",
      "\n",
      "CincinnatiAug1_2019.txt\n",
      "Found 652 unique words.\n",
      "Previewing upto 7 random ones: ['sharon', 'problems', 'devastate', 'peanuts', 'use,', 'breathe,', 'thought.'])\n",
      "-------------------------\n",
      "\n",
      "FayettevilleSep19_2020.txt\n",
      "Found 1733 unique words.\n",
      "Previewing upto 7 random ones: ['anti-american', 'announce,', 'allies', 'lethal,', 'safe.\"', 'ragged.', 'police,'])\n",
      "-------------------------\n",
      "\n",
      "WildwoodJan28_2020.txt\n",
      "Found 995 unique words.\n",
      "Previewing upto 7 random ones: ['past', 'motion', 'nervous', 'farms', 'authorized', 'army', 'interpret'])\n",
      "-------------------------\n",
      "\n",
      "GreenvilleJul17_2019.txt\n",
      "Found 2371 unique words.\n",
      "Previewing upto 7 random ones: ['important.', 'angry', 'nothing', 'places', '\"hey,', 'said,', 'control.'])\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview some of the unique terms!\n",
    "for speech, forms in unique_forms.items():\n",
    "    print(speech)\n",
    "    print(f'Found {len(forms)} unique words.')\n",
    "    print(f'Previewing upto 7 random ones: {list(forms)[:7]})')\n",
    "    print('-' * 25)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
